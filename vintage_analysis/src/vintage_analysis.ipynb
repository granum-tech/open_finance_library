{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the input file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Rename the uploaded file to 'input' with the correct extension\n",
    "for original_filename in uploaded.keys():\n",
    "    # Get the file extension\n",
    "    _, file_extension = os.path.splitext(original_filename)\n",
    "    # Define the new filename\n",
    "    new_filename = 'input' + file_extension\n",
    "    # Rename the file\n",
    "    os.rename(original_filename, new_filename)\n",
    "    # Set the file_path to the new filename\n",
    "    file_path = new_filename\n",
    "    print(f\"File uploaded and renamed to: {new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV or XLSX file into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please provide a CSV or XLSX file.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic data quality checks on the input DataFrame.\n",
    "    Prints warnings for potential issues but preserves data, this serves as a warning/insight.\n",
    "    'charge_off_date' NaN or None are replaced with NaT to be handled appropriately.\n",
    "    'net_call_off' NaN or None are replaced with 0.0 to be handled appropriately.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing loan servicing data\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): DataFrame containing loan servicing data\n",
    "\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Check for required columns\n",
    "    required_columns = ['loan_id', 'boarding_date', 'charge_off_date',\n",
    "                       'net_call_off', 'original_amount_financed']\n",
    "    missing_columns = set(required_columns) - set(df_copy.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "    # Convert dates - keep original if conversion fails\n",
    "    for date_col in ['boarding_date', 'charge_off_date']:\n",
    "        try:\n",
    "            df_copy[date_col] = pd.to_datetime(df_copy[date_col], errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Some {date_col} values could not be converted to dates\")\n",
    "\n",
    "    # Convert numeric columns - keep original if conversion fails\n",
    "    for num_col in ['net_call_off', 'original_amount_financed']:\n",
    "        try:\n",
    "            df_copy[num_col] = pd.to_numeric(df_copy[num_col], errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Some {num_col} values could not be converted to numbers\")\n",
    "\n",
    "    # Print warnings for potential data quality issues\n",
    "    issues_found = False\n",
    "\n",
    "    # Check only for critical missing values (boarding_date and original_amount_financed)\n",
    "    critical_missing = df_copy[['boarding_date', 'original_amount_financed']].isnull()\n",
    "    if critical_missing.any().any():\n",
    "        issues_found = True\n",
    "        print(\"\\nMissing required values:\")\n",
    "        missing_rows = df_copy[critical_missing.any(axis=1)]\n",
    "        print(\"loan_id | missing values\")\n",
    "        print(\"-\" * 30)\n",
    "        for idx, row in missing_rows.iterrows():\n",
    "            missing_cols = [col for col in ['boarding_date', 'original_amount_financed'] if pd.isnull(row[col])]\n",
    "            print(f\"{row['loan_id']} | {', '.join(missing_cols)}\")\n",
    "\n",
    "    # Check for charge-off dates before boarding dates\n",
    "    invalid_dates = df_copy[df_copy['charge_off_date'] < df_copy['boarding_date']]\n",
    "    if not invalid_dates.empty:\n",
    "        issues_found = True\n",
    "        print(\"\\nLoans with charge-off date before boarding date:\")\n",
    "        print(\"loan_id | boarding_date | charge_off_date\")\n",
    "        print(\"-\" * 50)\n",
    "        for idx, row in invalid_dates.iterrows():\n",
    "            print(f\"{row['loan_id']} | {row['boarding_date'].date()} | {row['charge_off_date'].date()}\")\n",
    "\n",
    "    # Check for duplicate loan_ids\n",
    "    duplicates = df_copy[df_copy['loan_id'].duplicated(keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        issues_found = True\n",
    "        print(\"\\nDuplicate loan_id entries:\")\n",
    "        print(\"loan_id | boarding_date\")\n",
    "        print(\"-\" * 30)\n",
    "        for idx, row in duplicates.iterrows():\n",
    "            print(f\"{row['loan_id']} | {row['boarding_date'].date()}\")\n",
    "\n",
    "    # Check for negative values\n",
    "    for col in ['original_amount_financed', 'net_call_off']:\n",
    "        negative_values = df_copy[df_copy[col] < 0]\n",
    "        if not negative_values.empty:\n",
    "            issues_found = True\n",
    "            print(f\"\\nNegative values found in {col}:\")\n",
    "            print(f\"loan_id | {col}\")\n",
    "            print(\"-\" * 30)\n",
    "            for idx, row in negative_values.iterrows():\n",
    "                print(f\"{row['loan_id']} | {row[col]}\")\n",
    "\n",
    "    # Basic data fixes\n",
    "    # Replace NaN or None to NaT to be handled as a blank time in pandas\n",
    "    df_copy['charge_off_date'] = df_copy['charge_off_date'].fillna(pd.NaT)\n",
    "    # Replace NaN or None with 0.0\n",
    "    df_copy['net_call_off'] = df_copy['net_call_off'].fillna(0.0)\n",
    "\n",
    "    if not issues_found:\n",
    "        print(\"No major data quality issues found\")\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vintage_matrix(df, period_type='quarterly', calculation_type='sum', output_file_path=None):\n",
    "    \"\"\"\n",
    "    Calculate the vintage matrix for cumulative net call-offs with flexible time period options.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing loan servicing data\n",
    "        period_type (str): Time period for analysis - 'monthly', 'quarterly', or 'yearly'\n",
    "        calculation_type (str): 'sum' for cumulative net call-off sum, 'percent' for percentage of cumulative amount financed for period\n",
    "        output_file_path (str): Path to save the output Excel file. If None, will generate default name\n",
    "\n",
    "    Returns:\n",
    "        vintage_matrix (pd.DataFrame): The calculated vintage matrix\n",
    "    \"\"\"\n",
    "    # Validate and set period parameters\n",
    "    period_settings = {\n",
    "        'monthly': {'freq': 'M', 'name': 'month'},\n",
    "        'quarterly': {'freq': 'Q', 'name': 'quarter'},\n",
    "        'yearly': {'freq': 'Y', 'name': 'year'}\n",
    "    }\n",
    "\n",
    "    if period_type.lower() not in period_settings:\n",
    "        raise ValueError(\"period_type must be 'monthly', 'quarterly', or 'yearly'\")\n",
    "\n",
    "    period_freq = period_settings[period_type.lower()]['freq']\n",
    "    period_name = period_settings[period_type.lower()]['name']\n",
    "\n",
    "    # Set default output file path if none provided\n",
    "    if output_file_path is None:\n",
    "        output_file_path = f'vintage_analysis_{period_type.lower()}_{calculation_type}.xlsx'\n",
    "\n",
    "    # Ensure datetime format for dates\n",
    "    df['boarding_date'] = pd.to_datetime(df['boarding_date'])\n",
    "    df['charge_off_date'] = pd.to_datetime(df['charge_off_date'])\n",
    "\n",
    "    # Add the period column based on boarding_date\n",
    "    period_col = f'year{period_name}'\n",
    "    df[period_col] = df['boarding_date'].dt.to_period(period_freq).astype(str)\n",
    "\n",
    "    # Calculate the number of periods since vintage started\n",
    "    def calculate_period_offset(row):\n",
    "        if pd.isna(row['charge_off_date']):\n",
    "            charge_off_period = pd.Timestamp.now().to_period(period_freq)\n",
    "        else:\n",
    "            charge_off_period = row['charge_off_date'].to_period(period_freq)\n",
    "        boarding_period = row['boarding_date'].to_period(period_freq)\n",
    "        return (charge_off_period - boarding_period).n\n",
    "\n",
    "    vintage_col = f'vintage_{period_name}'\n",
    "    df[vintage_col] = df.apply(calculate_period_offset, axis=1)\n",
    "\n",
    "    # Replace any missing net_call_off values with 0\n",
    "    df['net_call_off'] = df['net_call_off'].fillna(0)\n",
    "\n",
    "    # Calculate the total original amount financed for each vintage\n",
    "    origination_sum = df.groupby(period_col)['original_amount_financed'].sum()\n",
    "\n",
    "    # Group by period and vintage to calculate cumulative net_call_off\n",
    "    cumulative_data = (\n",
    "        df.groupby([vintage_col, period_col])['net_call_off']\n",
    "        .sum()\n",
    "        .groupby(level=1)\n",
    "        .cumsum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if calculation_type == 'percent':\n",
    "        cumulative_data['origination_sum'] = cumulative_data[period_col].map(origination_sum)\n",
    "        cumulative_data['net_call_off'] = (\n",
    "            cumulative_data['net_call_off'] / cumulative_data['origination_sum']\n",
    "        ) * 100\n",
    "\n",
    "    # Pivot to create the matrix\n",
    "    vintage_matrix = cumulative_data.pivot(\n",
    "        index=vintage_col, columns=period_col, values='net_call_off'\n",
    "    )\n",
    "\n",
    "    # Create a separate DataFrame for originations\n",
    "    originations_df = pd.DataFrame(origination_sum).T.rename(index={0: 'originations'})\n",
    "\n",
    "    # Get the maximum number of vintage periods\n",
    "    max_vintage_periods = len(vintage_matrix.index)\n",
    "\n",
    "    # Process each column to handle empty cells and value forwarding\n",
    "    for col in vintage_matrix.columns:\n",
    "        col_idx = vintage_matrix.columns.get_loc(col)\n",
    "        limit = max_vintage_periods - col_idx  # Diagonal cutoff limit\n",
    "\n",
    "        if limit > 0:\n",
    "            # Get the column data\n",
    "            column_data = vintage_matrix[col].copy()\n",
    "\n",
    "            # Find the first non-null value\n",
    "            first_valid_idx = column_data.first_valid_index()\n",
    "\n",
    "            if first_valid_idx is not None:\n",
    "                # Fill with 0s up to first valid value\n",
    "                column_data.loc[:first_valid_idx] = column_data.loc[:first_valid_idx].fillna(0)\n",
    "                # Forward fill the remaining values up to the limit\n",
    "                column_data = column_data.iloc[:limit].fillna(method='ffill')\n",
    "            else:\n",
    "                # If no valid values, fill everything up to limit with 0\n",
    "                column_data.iloc[:limit] = 0\n",
    "\n",
    "            # Apply back to vintage matrix\n",
    "            vintage_matrix[col].iloc[:limit] = column_data[:limit]\n",
    "\n",
    "    # Combine originations with vintage matrix\n",
    "    vintage_matrix = pd.concat([originations_df, vintage_matrix])\n",
    "\n",
    "    # Save the final vintage matrix to an Excel file\n",
    "    vintage_matrix.to_excel(output_file_path)\n",
    "    print(f\"{period_type.capitalize()} vintage matrix saved to {output_file_path}\")\n",
    "\n",
    "    return vintage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(new_filename)\n",
    "df = validate_data(df)\n",
    "quarterly_matrix = calculate_vintage_matrix(df, period_type='quarterly', calculation_type='percent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
